{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 73290,
          "databundleVersionId": 8710574,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "PSS_S4E6 || LightGB",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e6:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F73290%2F8710574%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240620%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240620T082604Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3f314103e87b6a9898f4d77a8ad693f020eb19223a23d0635e3d3020ff42861e89da46f7a5f31159a57f8fc16232617a3b40e52095dc924239bfe70d9096820a390a43e736d81617ec84c2ea65e55658c725d536c1d7feb9c2839d7b047cbc35e47d6079716e7658b24a69d529d767e85043165387e54705960514f4714f7eb5f7c90f45fc5d71b44115edd9ceaa021cf4532dc5947245b5a98fcebaa755f5bc2fc575086ba30364c2ae2e4d03f31965740be6c03bc351788faf63f52715449b16d5c0056644260d2dbab5040b9b88ff3542b620eddd0fc23cb57437bc3fd39868b5aea1b7e5424de60ed5fb0ae07ed1ee73bb9b96f786f4b1c9b999882a704e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LyfrEpkawMuD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:21.846924Z",
          "iopub.execute_input": "2024-06-20T08:11:21.847316Z",
          "iopub.status.idle": "2024-06-20T08:11:21.861161Z",
          "shell.execute_reply.started": "2024-06-20T08:11:21.847286Z",
          "shell.execute_reply": "2024-06-20T08:11:21.860023Z"
        },
        "trusted": true,
        "id": "peXZHL0FwMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv(\"/kaggle/input/playground-series-s4e6/train.csv\")\n",
        "test_df=pd.read_csv(\"/kaggle/input/playground-series-s4e6/test.csv\")\n",
        "train_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.356334Z",
          "iopub.execute_input": "2024-06-20T08:11:22.357227Z",
          "iopub.status.idle": "2024-06-20T08:11:22.727243Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.357193Z",
          "shell.execute_reply": "2024-06-20T08:11:22.726233Z"
        },
        "trusted": true,
        "id": "xx1ZmRVUwMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.72895Z",
          "iopub.execute_input": "2024-06-20T08:11:22.729299Z",
          "iopub.status.idle": "2024-06-20T08:11:22.760097Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.729271Z",
          "shell.execute_reply": "2024-06-20T08:11:22.759015Z"
        },
        "trusted": true,
        "id": "A9qJR7q7wMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# create an instance of LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# apply the fit_transform method to the target variable\n",
        "train_df[\"Target\"] = le.fit_transform(train_df[\"Target\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.761225Z",
          "iopub.execute_input": "2024-06-20T08:11:22.761508Z",
          "iopub.status.idle": "2024-06-20T08:11:22.78652Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.761483Z",
          "shell.execute_reply": "2024-06-20T08:11:22.785455Z"
        },
        "trusted": true,
        "id": "1AQak1X-wMuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.788586Z",
          "iopub.execute_input": "2024-06-20T08:11:22.788935Z",
          "iopub.status.idle": "2024-06-20T08:11:22.829633Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.788902Z",
          "shell.execute_reply": "2024-06-20T08:11:22.828648Z"
        },
        "trusted": true,
        "id": "ZJbWPIaAwMuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop(['Target'], axis=1)\n",
        "y = train_df[['Target']]\n",
        "X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.831376Z",
          "iopub.execute_input": "2024-06-20T08:11:22.83168Z",
          "iopub.status.idle": "2024-06-20T08:11:22.872048Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.831655Z",
          "shell.execute_reply": "2024-06-20T08:11:22.871098Z"
        },
        "trusted": true,
        "id": "y2nunfBkwMuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "\n",
        "# Create a Decision Tree Classifier with specific hyperparameters\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=2, min_samples_leaf=12)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:22.87322Z",
          "iopub.execute_input": "2024-06-20T08:11:22.87352Z",
          "iopub.status.idle": "2024-06-20T08:11:23.691213Z",
          "shell.execute_reply.started": "2024-06-20T08:11:22.873494Z",
          "shell.execute_reply": "2024-06-20T08:11:23.690221Z"
        },
        "trusted": true,
        "id": "tWuKNtwAwMuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# If y is a DataFrame or Series, convert it to a 1D array\n",
        "if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
        "    y = y.values.ravel()  # Convert 'y' to a 1D array if it's a DataFrame or Series\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create a Random Forest Classifier with specific hyperparameters\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=200,             # Number of trees in the forest\n",
        "    criterion='entropy',          # Function to measure the quality of a split\n",
        "    max_depth=10,                 # Maximum depth of the tree\n",
        "    min_samples_split=2,          # Minimum number of samples required to split an internal node\n",
        "    min_samples_leaf=12,          # Minimum number of samples required to be at a leaf node\n",
        "    random_state=42               # Seed for reproducibility\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:23.693806Z",
          "iopub.execute_input": "2024-06-20T08:11:23.694253Z",
          "iopub.status.idle": "2024-06-20T08:11:44.22196Z",
          "shell.execute_reply.started": "2024-06-20T08:11:23.694214Z",
          "shell.execute_reply": "2024-06-20T08:11:44.220882Z"
        },
        "trusted": true,
        "id": "ztXjFRlLwMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Ensure y is a 1D array if it is a DataFrame or Series\n",
        "if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
        "    y = y.values.ravel()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create an XGBoost Classifier with specific hyperparameters\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,             # Number of trees in the forest\n",
        "    max_depth=10,                 # Maximum depth of the tree\n",
        "    learning_rate=0.1,            # Learning rate\n",
        "    subsample=0.8,                # Subsample ratio of the training instances\n",
        "    colsample_bytree=0.8,         # Subsample ratio of columns when constructing each tree\n",
        "    gamma=0,                      # Minimum loss reduction required to make a further partition\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'         # Evaluation metric for early stopping\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy (XGBoost):\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"Classification Report (XGBoost):\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:11:44.223117Z",
          "iopub.execute_input": "2024-06-20T08:11:44.223406Z",
          "iopub.status.idle": "2024-06-20T08:12:11.331121Z",
          "shell.execute_reply.started": "2024-06-20T08:11:44.223381Z",
          "shell.execute_reply": "2024-06-20T08:12:11.330156Z"
        },
        "trusted": true,
        "id": "Ob6fyiThwMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Ensure y is a 1D array if it is a DataFrame or Series\n",
        "if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
        "    y = y.values.ravel()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create a CatBoost Classifier with specific hyperparameters\n",
        "cat_clf = CatBoostClassifier(\n",
        "    iterations=200,               # Number of boosting iterations\n",
        "    depth=10,                     # Depth of the tree\n",
        "    learning_rate=0.1,            # Learning rate\n",
        "    l2_leaf_reg=3,                # L2 regularization coefficient\n",
        "    random_state=42,\n",
        "    verbose=0                     # Silent output\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "cat_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_cat = cat_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy (CatBoost):\", accuracy_score(y_test, y_pred_cat))\n",
        "print(\"Classification Report (CatBoost):\")\n",
        "print(classification_report(y_test, y_pred_cat))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:12:11.333626Z",
          "iopub.execute_input": "2024-06-20T08:12:11.334167Z",
          "iopub.status.idle": "2024-06-20T08:12:40.655682Z",
          "shell.execute_reply.started": "2024-06-20T08:12:11.334126Z",
          "shell.execute_reply": "2024-06-20T08:12:40.654718Z"
        },
        "trusted": true,
        "id": "R45rjHgkwMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming X and y are your features and labels\n",
        "\n",
        "# Ensure y is a 1D array if it is a DataFrame or Series\n",
        "if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
        "    y = y.values.ravel()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create a LightGBM Classifier with specific hyperparameters\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=200,             # Number of boosting iterations\n",
        "    max_depth=10,                 # Maximum depth of each tree\n",
        "    learning_rate=0.1,            # Learning rate\n",
        "    subsample=0.8,                # Subsample ratio of the training instances\n",
        "    colsample_bytree=0.8,         # Subsample ratio of columns when constructing each tree\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lgb = lgb_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy (LightGBM):\", accuracy_score(y_test, y_pred_lgb))\n",
        "print(\"Classification Report (LightGBM):\")\n",
        "print(classification_report(y_test, y_pred_lgb))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:12:40.657412Z",
          "iopub.execute_input": "2024-06-20T08:12:40.657705Z",
          "iopub.status.idle": "2024-06-20T08:12:51.726839Z",
          "shell.execute_reply.started": "2024-06-20T08:12:40.65768Z",
          "shell.execute_reply": "2024-06-20T08:12:51.725799Z"
        },
        "trusted": true,
        "id": "8N4jX2qpwMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "\n",
        "# Make predictions using the LightGBM model\n",
        "y_pred_lgb = lgb_clf.predict(test_df)\n",
        "\n",
        "# Create a DataFrame for submission with 'id' and 'Target' columns\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],    # Assuming 'id' column exists in test_df\n",
        "    'Target': y_pred_lgb    # Predicted labels\n",
        "})\n",
        "\n",
        "# Save the submission DataFrame to a CSV file without row indices\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Optionally, display the first few rows of the submission DataFrame\n",
        "print(submission.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-20T08:12:51.728173Z",
          "iopub.execute_input": "2024-06-20T08:12:51.728486Z",
          "iopub.status.idle": "2024-06-20T08:12:53.800866Z",
          "shell.execute_reply.started": "2024-06-20T08:12:51.728458Z",
          "shell.execute_reply": "2024-06-20T08:12:53.799834Z"
        },
        "trusted": true,
        "id": "jCWW21zSwMuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zArngXfMwMuJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}